{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMiugv3+1l0Zcf34t/1hqyO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryakkalauncc/3162project3/blob/main/ITCS3162Project3Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Introduction:***\n",
        "The dataset I'm using in my analysis is the Exploring Student Acheivement Trends dataset from Kaggle, which explores the records of a 1,000 students with each record containing socioeconomic, demographic, and educational factors. It also encompasses the math, reading, and writing test scores of each student. The goal is to predict student academic performance specifically through their math scores, using demographic and educational factors.\n"
      ],
      "metadata": {
        "id": "rXyO1AWUESjG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is regression and how does it work?\n",
        "Regression is a machine learning technique used to predict a a continuous target variable. In this context, the goal is to predict student's math scores based on their reading and writing scores, demograpahics, and educational factors.\n",
        "Liner regression models a linear relationship between input variables (features) and the output (target)."
      ],
      "metadata": {
        "id": "R7mdGkt5EYv3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiments**\n",
        "1. Baseline Linear Regression\n",
        "2. Linear Regression\n",
        "3. Ridge Regression\n"
      ],
      "metadata": {
        "id": "ok4tNm6sEeoO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 1**"
      ],
      "metadata": {
        "id": "480bI9FqdQqt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qnX678x6EF1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3323031-2887-4b7d-c910-22eb58c6b1bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment 1: Baseline Linear Regression RMSE 8.788798451027851\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"StudentsPerformance.csv\")\n",
        "X = df[[\"reading score\",\"writing score\"]]\n",
        "y = df[\"math score\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(\"Experiment 1: Baseline Linear Regression RMSE\", rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Findings: The RMSE was a 8.79 indicating that on average, the model's predications were about 8.8 points away from actual math scores. This model demonstrates that while reading and writing scores are correlated with math achievement, additional context from other features is needed to improve accuracy."
      ],
      "metadata": {
        "id": "iBQ3JGkOjmvV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 2**"
      ],
      "metadata": {
        "id": "9gjzAJDBEweM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"StudentsPerformance.csv\")\n",
        "df[\"average_score\"] = (df[\"reading score\"] + df[\"writing score\"])/2\n",
        "X = df.drop(columns = [\"math score\"])\n",
        "y = df[\"math score\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20,random_state=42)\n",
        "\n",
        "categorical_columns = [\n",
        "    \"gender\",\n",
        "    \"race/ethnicity\",\n",
        "    \"parental level of education\",\n",
        "    \"lunch\",\n",
        "    \"test preparation course\"\n",
        "]\n",
        "numeric_columns = [\"reading score\", \"writing score\", \"average_score\"]\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"cat\", OneHotEncoder(drop = \"first\"), categorical_columns),\n",
        "        (\"num\", StandardScaler(), numeric_columns)\n",
        "    ],\n",
        "    remainder = \"drop\"\n",
        ")\n",
        "model = Pipeline(steps = [(\"preprocessor\", preprocessor), (\"regressor\", LinearRegression())])\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(\"Experiment 2: Linear Regression RMSE\", rmse)"
      ],
      "metadata": {
        "id": "BxAa1KSLtMr1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00feeea2-d6a8-44de-b657-5f0f7c8d1182"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment 2: Linear Regression RMSE 5.393993869732843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Findings: New variable average_score was created to combine reading and writing scores into 1 metric. Categorical variables were introduced through one-hot encoding. All numeric features were standardized. The RMSE dropped to 5.39 this demonstrates that incorporating categorical and contextual features providees more information for the model to learn from. Standardizing numeric inputs helps stabilize regression coefficients. Overall, the experiment shows how feature inclusion and preprocessing improves model performance."
      ],
      "metadata": {
        "id": "tbYyjfDojpug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 3**"
      ],
      "metadata": {
        "id": "YYG8CL4GEzR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"StudentsPerformance.csv\")"
      ],
      "metadata": {
        "id": "nUCM1cSaaktD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"average_score\"] = (df[\"reading score\"] + df[\"writing score\"])/2\n",
        "X = df.drop(columns = [\"math score\"])\n",
        "y = df[\"math score\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20,random_state=42)\n",
        "\n",
        "categorical_columns = [\n",
        "    \"gender\",\n",
        "    \"race/ethnicity\",\n",
        "    \"parental level of education\",\n",
        "    \"lunch\",\n",
        "    \"test preparation course\"\n",
        "]\n",
        "numeric_columns = [\"reading score\", \"writing score\", \"average_score\"]\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"cat\", OneHotEncoder(drop = \"first\"), categorical_columns),\n",
        "        (\"num\", StandardScaler(), numeric_columns)\n",
        "    ],\n",
        "    remainder = \"drop\"\n",
        ")\n",
        "\n",
        "ridge_pipeline = Pipeline(steps = [(\"preprocessor\", preprocessor), (\"model\", Ridge(alpha=1.0))])\n",
        "ridge_pipeline.fit(X_train, y_train)\n",
        "y_pred = ridge_pipeline.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(\"Experiment 3: Ridge Regression RMSE\" , rmse)"
      ],
      "metadata": {
        "id": "aba_JrmiE22N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34e3dab0-f0dd-42ac-8a2a-ef4d675a8783"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment 3: Ridge Regression RMSE 5.393451465682586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Findings: A ridge regression model was used instead of linear regression. Using L2 regularizatino, which penalizes large coefficient values to prevent overfitting. The ridge model achieved an RMSE of 5.39, suggesting that the model was not overfitting in experiment 2 so regularizatino offered marginal improvement. Ridge regression adds robustness and stability to the model, making it less sensitive to variations in the data regardless."
      ],
      "metadata": {
        "id": "dTOJF10ajrtN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Impact:**\n",
        " The impact of this project can extend into both educational and ethical policy debates. By building models that predict student performance, policymakers, school staff, parents, and even students can identify who may need additional academic support more effectively. This can also lead to proper resource allocation and promote a more inclusive education system. There are ethical concerns that can arise, such as the race/ethnicity or parental education factors. Models can potentially reinforce bias concerns. To combat such concerns, models should be used as informational resources and not to make high-stakes decisions. I believe this project can make light of where educational resources can be improved upon."
      ],
      "metadata": {
        "id": "LYxnK8gEFEDS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion:**\n",
        "Through this project, I explored how different levels of model complexity and preprocessing affect the accuracy of predicting student math scores based on demographic, socioeconomic, and educational factors. The first experiment was a baseline linear regression model that used only numeric reading and writing scores. This provided a simple benchmark for performance, showing how these scores correlate with math performance. In the second experiment, I expanded the model to include all categorical and numeric features such as gender, race/ethnicity, parental education level, lunch type, test preparation, and  course participation. After applying one-hot encoding and feature scaling, the model's performance improved, demonstrating that background and demographic variables provide additional explanatory power. The third experiment leveraged ridge regression. This adds an L2 regularization term to prevent overfitting. While this model may not always reduce RMSE, it generally stabilizes the model's weights and improves generalization to unseen data. The slight improvement showed that regularization can enhance model robustness."
      ],
      "metadata": {
        "id": "5SDVuMrrFGvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**References**\n",
        "** I leveraged Chat-GPT 5 and Grammarly to improve upon grammar and sentence structure throughout the written sections of this report."
      ],
      "metadata": {
        "id": "FutgSkSjFKCt"
      }
    }
  ]
}